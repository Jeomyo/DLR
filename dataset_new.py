#!/usr/bin/env python3
import os
import json

import cv2
import numpy as np
import pickle

from PIL import Image

import torch
from torch.utils.data import Dataset

from nuscenes.utils.data_classes import LidarPointCloud
from mapillary_coarse8 import remap_semantic_to_8, IGNORE_INDEX, NUM_SEM_CLASSES

from utils import (
    project_3d_to_2d,
    get_depth_map,
    colorize_depth_map,  # __main__ì—ì„œ ì“°ë¯€ë¡œ ì—¬ê¸°ë¡œ ì˜¬ë¦¼
)


class conf:
    input_h, input_w = 900, 1600
    max_depth = 80
    min_depth = 0
    query_radius = 3.0


rng = np.random.default_rng()


def random_hflip(img, depth, depth_mask, p=0.5, extra=None):
    """
    img, depth, depth_mask: (C, H, W) numpy ë°°ì—´
    extra: ê°™ì´ ë’¤ì§‘ì–´ì•¼ í•˜ëŠ” ì¶”ê°€ ë§µ ë¦¬ìŠ¤íŠ¸ (ê°ê° (C, H, W))
    """
    if extra is None:
        extra = []

    if rng.uniform(0.0, 1.0) > p:
        return img, depth, depth_mask, extra

    # numpy flip + copy ë¡œ stride ì–‘ìˆ˜ë¡œ ë³´ì •
    img = np.flip(img, axis=2).copy()          # W ì¶•
    depth = np.flip(depth, axis=2).copy()
    depth_mask = np.flip(depth_mask, axis=2).copy()
    extra_flipped = [np.flip(e, axis=2).copy() for e in extra]

    return img, depth, depth_mask, extra_flipped


class Vidar(torch.utils.data.Dataset):

    path = '/mnt/nas/mlmlab/data/nuscenes/nuscenes_infos_train.pkl'

    data_root = '/mnt/nas/mlmlab/data/nuscenes/'

    mono_depth_root = '/mnt/nas/mlmlab/data/mono_depth_pro'

    panoptic_root = '/home/jhkim/jeomyo/pseudo_panoptic'

    def __init__(self):
        with open(self.path, 'rb') as f:
            infos = pickle.load(f)

        # ìš°ë¦¬ê°€ í™•ì¸í•œ êµ¬ì¡°: {'metainfo': ..., 'data_list': [...]}
        if isinstance(infos, dict) and 'data_list' in infos:
            self.infos = infos['data_list']
        else:
            self.infos = infos

        # DLR-lite: only front camera & lidar
        self.camera_use_type = 'CAM_FRONT'
        self.lidar_use_type = 'LIDAR_TOP'

    def __len__(self):
        return len(self.infos)

    # -----------------------------
    # Panoptic ë¡œë”© helper
    # -----------------------------
    def load_panoptic(self, cam_info, depth_mask_np):
        """
        cam_infoì™€ depth_maskë¥¼ ë°›ì•„ì„œ
        - pp_inst: (1, H, W) int32   (instance id, 0 = no instance/sky/void)
        - pp_sem:  (1, H, W) int16   (category_id, 0 = unknown/ì—†ìŒ)
        - pp_valid_mask: (1, H, W) uint8 (depth ìœ íš¨ & instance ì¡´ì¬í•˜ëŠ” í”½ì…€)
        ì„ ë¦¬í„´í•œë‹¤.

        ì „ì œ:
        - sky ì œê±° ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì´ë¯¸ ëŒë ¤ì„œ sky segmentëŠ” JSON/PNGì—ì„œ ë¹ ì ¸ìˆë‹¤.
        - panoptic PNG / JSON í•´ìƒë„ëŠ” CAM_FRONT ì´ë¯¸ì§€ì™€ ë™ì¼í•˜ë‹¤.
        - íŒŒì¼ ì´ë¦„ ê·œì¹™:
          <img_basename>_panoptic.json
          <img_basename>_panopticId.png
        """
        base = os.path.basename(cam_info['img_path'])  # ì˜ˆ: n015-...jpg
        stem, _ = os.path.splitext(base)

        json_path = os.path.join(self.panoptic_root, stem + "_panoptic.json")
        png_path = os.path.join(self.panoptic_root, stem + "_panopticId.png")

        if (not os.path.exists(json_path)) or (not os.path.exists(png_path)):
            # panopticì´ ì—†ëŠ” ê²½ìš°: ì „ë¶€ 0ìœ¼ë¡œ ì±„ìš°ê³  valid_maskë„ 0
            _, H, W = depth_mask_np.shape
            pp_inst = np.zeros((1, H, W), dtype=np.int32)
            pp_sem = np.zeros((1, H, W), dtype=np.int16)
            pp_valid_mask = np.zeros((1, H, W), dtype=np.uint8)
            return pp_inst, pp_sem, pp_valid_mask

        # JSON ë¡œë“œ
        with open(json_path, "r") as f:
            ann = json.load(f)
        segments = ann.get("segments_info", [])

        # PNG ë¡œë“œ: (H, W)
        pan = np.array(Image.open(png_path)).astype(np.int32)
        H_pan, W_pan = pan.shape[:2]

        # depth_maskì™€ í•´ìƒë„ ë§ëŠ”ì§€ í™•ì¸
        _, H_d, W_d = depth_mask_np.shape
        assert (H_pan, W_pan) == (H_d, W_d), \
            f"Panoptic size {H_pan,W_pan} != depth size {H_d,W_d} for {png_path}"

        # instance id map
        inst_map = pan  # (H, W), int32

        # semantic id map
        sem_map = np.zeros_like(inst_map, dtype=np.int16)
        for seg in segments:
            sid = seg["id"]
            cid = seg["category_id"]
            mask = (inst_map == sid)
            sem_map[mask] = cid

        sem_map_8 = remap_semantic_to_8(sem_map, ignore_index=IGNORE_INDEX) 

        # instanceê°€ ì¡´ì¬í•˜ëŠ” í”½ì…€ (0ì€ no-instance / sky / void ë“±)
        has_inst = (inst_map > 0).astype(np.uint8)  # (H, W)

        # depth_mask_np: (1, H, W) â†’ (H, W)
        depth_valid = (depth_mask_np[0] > 0).astype(np.uint8)

        # ìµœì¢… valid mask: depthë„ ìˆê³  instanceë„ ìˆëŠ” í”½ì…€ë§Œ 1
        valid_mask = has_inst.astype(np.uint8)  # (H, W)
        valid_mask[sem_map_8 == IGNORE_INDEX] = 0

        # CHWë¡œ reshape
        pp_inst = inst_map.astype(np.int32)[None, ...]          # (1, H, W)
        pp_sem  = sem_map_8.astype(np.int16)[None, ...]            # (1, H, W)
        pp_valid_mask = valid_mask.astype(np.uint8)[None, ...]  # (1, H, W)

        return pp_inst, pp_sem, pp_valid_mask

    def __getitem__(self, index):
        data = self.infos[index]

        # ============================
        # 1) CAM_FRONT ì´ë¯¸ì§€ ë¡œë“œ (mmdet3d-style)
        # ============================
        cam_info = data['images'][self.camera_use_type]

        # img_path: 'n015-...jpg' â†’ <root>/samples/CAM_FRONT/<img_path>
        img_path = os.path.join(
            self.data_root, 'samples', self.camera_use_type, cam_info['img_path']
        )
        img = cv2.imread(img_path)  # BGR, HxWx3
        if img is None:
            raise FileNotFoundError(f"Image not found: {img_path}")

        H, W = img.shape[:2]

        # ============================
        # 2) LIDAR_TOP ë¡œë“œ
        # ============================
        lidar_info = data['lidar_points']
        lidar_path = os.path.join(
            self.data_root, 'samples', self.lidar_use_type, lidar_info['lidar_path']
        )

        lidar_obj = LidarPointCloud.from_file(lidar_path)
        pts_lidar = lidar_obj.points[:3, :].T  # (N, 3) xyz (LiDAR frame)

        # ë™ì°¨ ì¢Œí‘œ (x, y, z, 1)
        N = pts_lidar.shape[0]
        pts_h = np.concatenate(
            [pts_lidar, np.ones((N, 1), dtype=pts_lidar.dtype)],
            axis=1
        )  # (N, 4)

        # ============================
        # 3) LiDAR â†’ Camera ë³€í™˜ (lidar2cam + cam2img)
        # ============================
        lidar2cam = np.array(cam_info['lidar2cam'], dtype=np.float32)  # (4, 4)
        cam2img = np.array(cam_info['cam2img'], dtype=np.float32)      # (3, 3)

        pts_cam = (lidar2cam @ pts_h.T).T   # (N, 4)
        xyz_cam = pts_cam[:, :3]
        z_cam = xyz_cam[:, 2]

        # ê¹Šì´ ë²”ìœ„ í•„í„°
        valid = (z_cam > conf.min_depth) & (z_cam < conf.max_depth)
        xyz_cam = xyz_cam[valid]
        z_cam = z_cam[valid]

        # ì¹´ë©”ë¼ í‰ë©´ìœ¼ë¡œ íˆ¬ì˜
        if xyz_cam.shape[0] == 0:
            # ì´ í”„ë ˆì„ì— ìœ íš¨ LiDAR í¬ì¸íŠ¸ê°€ 0ê°œì¸ ê²½ìš° ë°©ì–´
            depth_np = np.zeros((H, W), dtype=np.float32)
        else:
            uv = project_3d_to_2d(xyz_cam, cam2img)  # (N, 2) [u, v]
            # (u, v, depth) â†’ depth map ìƒì„±
            lidar_uvd = np.concatenate([uv, z_cam[:, None]], axis=1)  # (N, 3)
            depth_np = get_depth_map(lidar_uvd, (H, W))  # (H, W), float32

        # ============================
        # 4) numpy / shape ì •ë¦¬
        # ============================
        # img: BGR(H,W,3) â†’ CHW (3,H,W)
        img_np = np.ascontiguousarray(img.transpose(2, 0, 1))  # (3, H, W)

        depth_mask_np = (depth_np > 0).astype(np.uint8)
        depth_np = depth_np.astype('float32')

        depth_np = depth_np[None, ...]           # (1, H, W)
        depth_mask_np = depth_mask_np[None, ...] # (1, H, W)

        # ============================
        # 4.5) DepthPro teacher depth ë¡œë“œ
        # ============================
        # img íŒŒì¼ ì´ë¦„ì—ì„œ stem ì¶”ì¶œ
        img_base = os.path.basename(cam_info['img_path'])  # n008-...__CAM_FRONT__1526915243012465.jpg
        stem, _ = os.path.splitext(img_base)               # n008-...__CAM_FRONT__1526915243012465

        teacher_path = os.path.join(self.mono_depth_root, stem + '.npy')

        if os.path.exists(teacher_path):
            teacher_np = np.load(teacher_path).astype('float32')  # (H, W) or (1,H,W)
            if teacher_np.ndim == 2:
                teacher_np = teacher_np[None, ...]  # (1, H, W)
        else:
            # ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì±„ìš°ê¸°
            _, H, W = depth_np.shape
            teacher_np = np.zeros((1, H, W), dtype=np.float32)

        teacher_np = np.clip(teacher_np, conf.min_depth, conf.max_depth)

        # ============================
        # 5) Panoptic pseudo-GT ë¡œë“œ
        # ============================
        pp_inst_np, pp_sem_np, pp_valid_mask_np = self.load_panoptic(
            cam_info, depth_mask_np
        )

        # ============================
        # 6) Augmentation: Horizontal Flip
        # ============================
        extras = [teacher_np, pp_inst_np, pp_sem_np, pp_valid_mask_np]
        img_np, depth_np, depth_mask_np, extras = random_hflip(
            img_np, depth_np, depth_mask_np, p=0.5, extra=extras
        )
        teacher_np, pp_inst_np, pp_sem_np, pp_valid_mask_np = extras

        # ============================
        # 7) íŠœí”Œë¡œ ë°˜í™˜
        # ============================
        # íŠœí”Œ ìˆœì„œ:
        #   0: img           (3, H, W)
        #   1: depth         (1, H, W)
        #   2: depth_mask    (1, H, W)
        #   3: pp_inst       (1, H, W)
        #   4: pp_sem        (1, H, W)
        #   5: pp_valid_mask (1, H, W)
        return (
            img_np,
            depth_np,
            depth_mask_np,
            pp_inst_np,
            pp_sem_np,
            pp_valid_mask_np,
            teacher_np,         # ğŸ”¹ ì¶”ê°€: (1, H, W)
        )


if __name__ == '__main__':

    def make_depth_overlay(img_chw, depth_1hw, mask_1hw, alpha=0.6):
        """
        img_chw: (3, H, W) BGR
        depth_1hw: (1, H, W) float32 depth (meters)
        mask_1hw: (1, H, W) uint8 (0/1)
        """
        img_vis = img_chw.transpose(1, 2, 0).astype(np.float32)  # (H, W, 3)
        d = depth_1hw.squeeze()                                  # (H, W)
        m = mask_1hw.squeeze().astype(bool)                      # (H, W)

        d_clipped = np.clip(d, 0, 80) / 80.0
        depth_color = colorize_depth_map(d_clipped).astype(np.float32)  # (H,W,3)

        overlay = img_vis.copy()
        overlay[m] = (1 - alpha) * img_vis[m] + alpha * depth_color[m]
        overlay = np.clip(overlay, 0, 255).astype(np.uint8)
        return img_vis.astype(np.uint8), depth_color.astype(np.uint8), overlay

    def visualize_panoptic_sem(pp_sem_1hw, valid_mask_1hw=None):
        sem = pp_sem_1hw.squeeze().astype(np.int32)  # (H, W)

        # 1) ì‹œê°í™”ìš© ë³µì‚¬ë³¸ ë§Œë“¤ê³  IGNOREëŠ” 0ìœ¼ë¡œ ì²˜ë¦¬
        sem_vis = sem.copy()
        sem_vis[sem_vis == IGNORE_INDEX] = 0

        # 2) 0 ~ NUM_SEM_CLASSES-1 ë²”ìœ„ ê¸°ì¤€ìœ¼ë¡œ ì •ê·œí™”
        max_label = max(1, NUM_SEM_CLASSES - 1)  # ì˜ˆ: 8-classë©´ 7
        sem_norm = (sem_vis.clip(0, max_label).astype(np.float32) / max_label) * 255.0
        sem_norm = sem_norm.astype(np.uint8)

        sem_color = cv2.applyColorMap(sem_norm, cv2.COLORMAP_JET)

        # 3) valid_mask ìˆìœ¼ë©´ ê·¸ ì™¸ëŠ” ê¹Œë§£ê²Œ
        if valid_mask_1hw is not None:
            vm = valid_mask_1hw.squeeze().astype(bool)
            sem_color[~vm] = 0

        return sem_color

    def overlay_mask_on_img(img_hw3, mask_hw, color=(0, 0, 255), alpha=0.5):
        """
        img_hw3: (H, W, 3) BGR
        mask_hw: (H, W) uint8 0/1
        """
        img = img_hw3.astype(np.float32).copy()
        mask = mask_hw.astype(bool)

        overlay = img.copy()
        color_arr = np.zeros_like(img)
        color_arr[:, :] = np.array(color, dtype=np.float32)

        overlay[mask] = (1 - alpha) * img[mask] + alpha * color_arr[mask]
        overlay = np.clip(overlay, 0, 255).astype(np.uint8)
        return overlay

    # ============================
    # 0) ìƒ˜í”Œ í•˜ë‚˜ ë½‘ê¸°
    # ============================
    dataset = Vidar()
    (
        img,           # (3, H, W), BGR
        depth,         # (1, H, W)
        depth_mask,    # (1, H, W)
        pp_inst,       # (1, H, W)
        pp_sem,        # (1, H, W)
        pp_valid_mask, # (1, H, W)
        teacher_depth, # (1, H, W)  ğŸ”¹ ì¶”ê°€
    ) = dataset[0]


    # ============================
    # 0-1) ê¸°ë³¸ í†µê³„ ì¶œë ¥ (shape / dtype / ê°’ ë¶„í¬)
    # ============================
    print("img shape, dtype:", img.shape, img.dtype)
    print("depth shape, dtype:", depth.shape, depth.dtype)
    print("depth_mask shape, dtype:", depth_mask.shape, depth_mask.dtype)
    print("pp_inst shape, dtype:", pp_inst.shape, pp_inst.dtype)
    print("pp_sem shape, dtype:", pp_sem.shape, pp_sem.dtype)
    print("pp_valid_mask shape, dtype:", pp_valid_mask.shape, pp_valid_mask.dtype)
    print("teacher_depth shape, dtype:", teacher_depth.shape, teacher_depth.dtype)

    d = depth.squeeze()
    dm = depth_mask.squeeze()
    print("depth stats: min={:.4f}, max={:.4f}, mean={:.4f}".format(
        float(d.min()), float(d.max()), float(d.mean())
    ))
    td = teacher_depth.squeeze()
    print("teacher_depth stats: min={:.4f}, max={:.4f}, mean={:.4f}".format(
        float(td.min()), float(td.max()), float(td.mean())
    ))
    print("depth non-zero count:", int((d > 0).sum()))
    print("depth_mask unique:", np.unique(dm))

    print("pp_inst unique:", np.unique(pp_inst))
    print("pp_sem unique:", np.unique(pp_sem))
    print("pp_valid_mask unique:", np.unique(pp_valid_mask))

    # ============================
    # 1) depth overlay / raw ì €ì¥
    # ============================
    img_vis, depth_color, overlay = make_depth_overlay(img, depth, depth_mask)

    cv2.imwrite('raw_img.png', img_vis)                # BGR
    cv2.imwrite('raw_depth_color.png', depth_color)    # depth colormap
    cv2.imwrite('overlay_depth_on_img.png', overlay)   # overlay

    # ============================
    # 1-1) DepthPro teacher depth overlay / raw ì €ì¥
    # ============================
    # teacher_depthëŠ” denseì¼ ìˆ˜ ìˆì–´ì„œ maskëŠ” ì „ì²´ 1ë¡œ ë‘ê±°ë‚˜, (teacher_depth > 0)ë¡œ ì¤˜ë„ ë¨
    teacher_mask = (teacher_depth > 0).astype(np.uint8)

    img_vis_t, depth_color_t, overlay_t = make_depth_overlay(
        img, teacher_depth, teacher_mask
    )

    cv2.imwrite('teacher_depth_color.png', depth_color_t)
    cv2.imwrite('overlay_teacher_depth_on_img.png', overlay_t)

    # ============================
    # 2) panoptic semantic ì‹œê°í™”
    # ============================
    sem_color_full = visualize_panoptic_sem(pp_sem)  # valid_mask ì—†ì´ ì „ì²´ ì¹´í…Œê³ ë¦¬
    cv2.imwrite('panoptic_sem_color_full.png', sem_color_full)

    # depth âˆ© instance valid ì˜ì—­ë§Œ í‘œì‹œ
    sem_color_valid = visualize_panoptic_sem(pp_sem, pp_valid_mask)
    cv2.imwrite('panoptic_sem_color_valid.png', sem_color_valid)

    # ============================
    # 3) pp_valid_mask overlay ì‹œê°í™”
    # ============================
    vm = pp_valid_mask.squeeze().astype(np.uint8)  # (H, W)
    vm_overlay = overlay_mask_on_img(img_vis, vm, color=(0, 0, 255), alpha=0.5)
    cv2.imwrite('panoptic_valid_overlay.png', vm_overlay)

    # ============================
    # 4) flip í•¨ìˆ˜ ê²€ì¦ìš©: no-flip vs ê°•ì œ flip
    # ============================
    base_img    = img.copy()
    base_depth  = depth.copy()
    base_mask   = depth_mask.copy()
    base_extras = [pp_inst.copy(), pp_sem.copy(), pp_valid_mask.copy()]

    # (a) p=0.0 â†’ ì ˆëŒ€ ë’¤ì§‘ì§€ ì•ŠìŒ
    img_nf, depth_nf, mask_nf, extras_nf = random_hflip(
        base_img.copy(),
        base_depth.copy(),
        base_mask.copy(),
        p=0.0,
        extra=[e.copy() for e in base_extras],
    )
    pp_inst_nf, pp_sem_nf, pp_valid_nf = extras_nf

    img_nf_vis, depth_nf_color, overlay_nf = make_depth_overlay(
        img_nf, depth_nf, mask_nf
    )
    cv2.imwrite('noflip_overlay.png', overlay_nf)

    # (b) p=1.0 â†’ í•­ìƒ ê°•ì œ flip
    img_ff, depth_ff, mask_ff, extras_ff = random_hflip(
        base_img.copy(),
        base_depth.copy(),
        base_mask.copy(),
        p=1.0,
        extra=[e.copy() for e in base_extras],
    )
    pp_inst_ff, pp_sem_ff, pp_valid_ff = extras_ff

    img_ff_vis, depth_ff_color, overlay_ff = make_depth_overlay(
        img_ff, depth_ff, mask_ff
    )
    cv2.imwrite('flip_overlay.png', overlay_ff)

    # panoptic valid maskë„ flipëœ ë²„ì „ìœ¼ë¡œ overlay ë¹„êµ
    vm_nf = pp_valid_nf.squeeze().astype(np.uint8)
    vm_ff = pp_valid_ff.squeeze().astype(np.uint8)

    vm_nf_overlay = overlay_mask_on_img(
        img_nf_vis, vm_nf, color=(0, 0, 255), alpha=0.5
    )
    vm_ff_overlay = overlay_mask_on_img(
        img_ff_vis, vm_ff, color=(0, 255, 0), alpha=0.5
    )

    cv2.imwrite('noflip_panoptic_valid_overlay.png', vm_nf_overlay)
    cv2.imwrite('flip_panoptic_valid_overlay.png', vm_ff_overlay)

    print("Saved:")
    print("  raw_img.png")
    print("  raw_depth_color.png")
    print("  overlay_depth_on_img.png")
    print("  panoptic_sem_color_full.png")
    print("  panoptic_sem_color_valid.png")
    print("  panoptic_valid_overlay.png")
    print("  noflip_overlay.png / flip_overlay.png")
    print("  noflip_panoptic_valid_overlay.png / flip_panoptic_valid_overlay.png")
